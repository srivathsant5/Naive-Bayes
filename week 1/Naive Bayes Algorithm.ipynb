{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a35d269f",
   "metadata": {},
   "source": [
    "# Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f60a0e",
   "metadata": {},
   "source": [
    "##### Advantages of Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "raw",
   "id": "7de5e555",
   "metadata": {},
   "source": [
    "It is simple and easy to implement\n",
    "It doesn’t require as much training data\n",
    "It handles both continuous and discrete data\n",
    "It is highly scalable with the number of predictors and data points\n",
    "It is fast and can be used to make real-time predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b1660b",
   "metadata": {},
   "source": [
    "##### why is it so popular?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d473cfb",
   "metadata": {},
   "source": [
    "Since it is a probabilistic approach, the predictions can be made real quick.\n",
    "It can be used for both binary and multi-class classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a35d29",
   "metadata": {},
   "source": [
    "#### Conditional Probability for Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc27b2b2",
   "metadata": {},
   "source": [
    "Conditional probability is defined as the likelihood of an event or outcome occurring, based on the occurrence of a previous event or outcome. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "baaa2655",
   "metadata": {},
   "source": [
    " tossing 2 coins\n",
    "    S = {HH, HT, TH, TT}\n",
    "    If a person is asked to find the probability of getting a tail his answer would be 3/4 = 0.75\n",
    "    The probability of getting heads on both the coins will be 1/4 = 0.25\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ddeb81",
   "metadata": {},
   "source": [
    "![SNOWFALL](CP.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4e7bb",
   "metadata": {},
   "source": [
    "### Bayes’ Rule"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5d4b65b",
   "metadata": {},
   "source": [
    "Bayes' Theorem states that the conditional probability of an event, based on the occurrence of another event, is equal to the likelihood of the second event given the first event multiplied by the probability of the first event."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3363a3b1",
   "metadata": {},
   "source": [
    "![](BY1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d02a3",
   "metadata": {},
   "source": [
    "### What is Naive Bayes?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38d5acb8",
   "metadata": {},
   "source": [
    "When the features are independent, we can extend Bayes’ rule to what is called Naive Bayes which assumes that the features are independent that means changing the value of one feature doesn’t influence the values of other variables and this is why we call this algorithm “NAIVE”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4ed4f0",
   "metadata": {},
   "source": [
    "![](nv.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45c6098",
   "metadata": {},
   "source": [
    "##### Where is Naive Bayes Used?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a60c5ba7",
   "metadata": {},
   "source": [
    "Face Recognition\n",
    "Weather Prediction \n",
    "Medical Diagnosis \n",
    "News Classification \n",
    "spam filtration\n",
    "Sentimental analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c486f4",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf2d8f2",
   "metadata": {},
   "source": [
    "Gaussian Naïve Bayes is used when we assume all the continuous variables associated with each feature to be distributed according to Gaussian Distribution. Gaussian Distribution is also called Normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7488984",
   "metadata": {},
   "source": [
    "![](gb.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9353a22",
   "metadata": {},
   "source": [
    "# CASE 1: Shopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88db59",
   "metadata": {},
   "source": [
    "## Problem statement:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "033ea5a7",
   "metadata": {},
   "source": [
    " To predict whether a person will purchase a product on a specific combination of day, discount, and free delivery using a Naive Bayes classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b74e24",
   "metadata": {},
   "source": [
    "![](p1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec71f37",
   "metadata": {},
   "source": [
    "![](ps.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b66285",
   "metadata": {},
   "source": [
    "![](p2.PNG)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc77ccd6",
   "metadata": {},
   "source": [
    "For Bayes theorem, let the event ‘buy’ be A and the independent variables (discount, free delivery, day) be B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50978047",
   "metadata": {},
   "source": [
    " the main difference between the two is that a frequency table is used to keep track of the frequency of words in the corpus, while a likelihood table is used to keep track of the likelihood of a word given a class. Both tables are important for the Naive Bayes algorithm to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26596dee",
   "metadata": {},
   "source": [
    "![](p10.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c75ed72",
   "metadata": {},
   "source": [
    "The likelihood tables can be used to calculate whether a customer will purchase a product on a specific combination of the day when there is a discount and whether there is free delivery. Consider a combination of the following factors where B equals:\n",
    "\n",
    "\n",
    "Day = Holiday  (Saturday and Sunday)\n",
    "\n",
    "Discount = Yes\n",
    "\n",
    "Free Delivery = Yes \n",
    "\n",
    "Let us find the probability of them not purchasing based on the conditions above. \n",
    "\n",
    "\n",
    "A = No Purchase\n",
    "\n",
    "\n",
    "Applying Bayes Theorem, we get P(A | B) as shown:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f8f2ab",
   "metadata": {},
   "source": [
    "![](p6.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78727906",
   "metadata": {},
   "source": [
    "Here, A = Buy\n",
    "\n",
    "\n",
    "Applying Bayes Theorem, we get P(A | B) as shown:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec61ef8c",
   "metadata": {},
   "source": [
    "![](p7.PNG)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c251f1bf",
   "metadata": {},
   "source": [
    "From the two calculations above, we find that:\n",
    "\n",
    "Probability of purchase = 0.986 \n",
    "\n",
    "Probability of no purchase = 0.178\n",
    "\n",
    "Finally, we have a conditional probability of purchase on this day.\n",
    "\n",
    "Next,  normalize these probabilities to get the likelihood of the events:\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c0ec848",
   "metadata": {},
   "source": [
    "Sum of probabilities = 0.986 + 0.178 = 1.164\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13d6b359",
   "metadata": {},
   "source": [
    "Likelihood of purchase = 0.986 / 1.164 = 84.71 percent\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "67a52020",
   "metadata": {},
   "source": [
    "Likelihood of no purchase = 0.178 / 1.164 = 15.29 percent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc5cf6",
   "metadata": {},
   "source": [
    "###### Result: As 84.71 percent is greater than 15.29 percent, we can conclude that an average customer will buy on holiday with a discount and free delivery."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4414110f",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Customer_Data.csv\")\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df[['discount', 'free_delivery','day']]\n",
    "y = df['buy']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e449c9c",
   "metadata": {},
   "source": [
    "# CASE 2: TEXT CLASSIFICATION TASK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cfec7e",
   "metadata": {},
   "source": [
    "### Multinomial Naiive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99faf543",
   "metadata": {},
   "source": [
    "    * Multinomial Naive Bayes is a variant of Naive Bayes for text classification tasks\n",
    "    * Models word counts in a document using a multinomial distribution\n",
    "    * Makes predictions based on the occurrence of words in a document and the probability of each class\n",
    "    * Known for simplicity, fast training/prediction times, and good performance on high-dimensional data\n",
    "    * Assumes independence between features (words), which may not always be the case\n",
    "    * Can be sensitive to irrelevant or low-frequency words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c909f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba270149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.50      0.67      0.56         3\n",
      "weighted avg       0.50      0.67      0.56         3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Data:\n",
    "train_texts = [\"This is positive text\", \"This is negative text\", \"This is positive text\", \"This is negative text\"]\n",
    "train_labels = [1, 0, 1, 0]\n",
    "\n",
    "test_texts = [\"This is positive text\", \"This is negative text\", \"This text is neutral\"]\n",
    "test_labels = [1, 0, 2]\n",
    "\n",
    "# Convert text into bag-of-words:\n",
    "vectorizer = CountVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "# Train the classifier:\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_vectors, train_labels)\n",
    "\n",
    "# Test the classifier:\n",
    "test_vectors = vectorizer.transform(test_texts)\n",
    "predictions = clf.predict(test_vectors)\n",
    "print(classification_report(test_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f60e95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
